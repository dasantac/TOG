# Load project's shell environment variables
import os
import sys
from dotenv import load_dotenv
load_dotenv(dotenv_path="../project.env")
sys.path.append(os.environ["PYTHONPATH"])

import warnings
warnings.filterwarnings(
    "ignore",
    message=".*",
    category=FutureWarning
)

###############################################################################
################################### Classes ###################################

big_classes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',  \
                'll', 'm', 'n', 'ñ', 'o', 'p', 'q', 'r', 'rr', 's', 't', 'u',\
                'v', 'w', 'x', 'y', 'z', '1', '2', '3', '4', '5', '6', '7',  \
                '8', '9', '10']
small_classes = ['0']
ALL_CLASSES_LIST = big_classes + small_classes
CLASSES_TO_NUMBERS = {ALL_CLASSES_LIST[i] : i for i in \
                      range(len(ALL_CLASSES_LIST))}
NUMBERS_TO_CLASSES = {i : ALL_CLASSES_LIST[i] for i in \
                      range(len(ALL_CLASSES_LIST))}

NUM_CLASSES = "two-classes"
#NUM_CLASSES = "three-classes"
#NUM_CLASSES = "six-classes"
#NUM_CLASSES = "ten-classes"
#NUM_CLASSES = "alpha-classes"
#NUM_CLASSES = "all-classes"

print(f"\n\nChosen class grouping: {NUM_CLASSES}\n\n")

def get_class_list(list_name):
  if list_name == "all-classes":
    class_list = ALL_CLASSES_LIST
  elif list_name == "two-classes":
    class_list = ['a', 'b']
  elif list_name == "three-classes":
    class_list = ['a', 'b', 'c']
  elif list_name == "six-classes":
    class_list = ['a', 'b', 'c', 'd', 'e', 'f']
  elif list_name == "ten-classes":
    class_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'l']
  elif list_name == "alpha-classes":
    class_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',  \
                  'll', 'm', 'n', 'ñ', 'o', 'p', 'q', 'r', 'rr', 's', 't', 'u',\
                  'v', 'w', 'x', 'y', 'z']
    
  return class_list

def get_class_numeric_list(class_list):
  return [CLASSES_TO_NUMBERS[c] for c in class_list]

CLASSES_LIST = get_class_list(NUM_CLASSES)
CLASSES_REGEX_GROUP = '|'.join(CLASSES_LIST)

################################### Classes ###################################
###############################################################################
############################### Hyperparameters ###############################

# PH1
NUM_FRAMES_EXTRACTED_PER_VIDEO_HALF = 6
NUM_FRAMES_PER_VIDEO = 2*NUM_FRAMES_EXTRACTED_PER_VIDEO_HALF

# PH3
PH3_N_CANDIDATES = [n for n in range(1,8)]

############################### Hyperparameters ###############################
###############################################################################
################################## Filesystem #################################

# Dataset naming
DATA_AH_PF='AHpf'
DATA_S_PF='Spf'
DATA_S_PV='Spv'

def report_dir_if_not_exists(path):
  if os.path.exists(path)==False:
    raise Exception(f"Directory {path} does not exist. Please investigate") 
  else:
    print(f"Directory {path} exists. Continuing with execution")

def create_dir_if_not_exists(path):
  if os.path.exists(path)==False:
    print(f"Directory {path} does not exist. Creating it and continuing with "\
           "execution")
    os.makedirs(path)
  else:
    print(f"Directory {path} exists. Continuing with execution")

# Top directory for the project
ROOT = os.environ["TOG_ROOT"]
report_dir_if_not_exists(ROOT)

# Directory where all the data used by and created by the project lives
DATA_ROOT = os.path.join(ROOT, 'data')
report_dir_if_not_exists(DATA_ROOT)

# Directory where all the code used for the project lives
CODE_ROOT = os.path.join(ROOT, 'src')
report_dir_if_not_exists(CODE_ROOT)

# Directory where all the binaries used by and created by the project live
BIN_ROOT = os.path.join(ROOT, 'bin')
report_dir_if_not_exists(BIN_ROOT)

# Directory where all the media used by and created by the project live
MEDIA_ROOT = os.path.join(ROOT, 'media')
report_dir_if_not_exists(MEDIA_ROOT)

# Directory where the scores for all the models trained lives
SCORES_ROOT = os.path.join(ROOT, 'scores')
report_dir_if_not_exists(SCORES_ROOT)

# Directory where the raw videos live
RAW_DATA_ROOT = os.path.join(DATA_ROOT, 'raw', 'all-classes')

# Directory where the extracted data from PH1 lives
PH1_DATA_ROOT = os.path.join(DATA_ROOT, 'PH1', NUM_CLASSES)
PH1_DATA_AH_PF_CSV = os.path.join(PH1_DATA_ROOT, f'{DATA_AH_PF}.csv')

# Directory where the data generated by PH2 lives
PH2_DATA_ROOT = os.path.join(DATA_ROOT, 'PH2', NUM_CLASSES)
PH2_DATA_AH_PF_CSV = os.path.join(PH2_DATA_ROOT, f'{DATA_AH_PF}.csv')

# Directory where the data generated by PH3 will live
PH3_DATA_ROOT = os.path.join(DATA_ROOT, 'PH3', NUM_CLASSES)
# Directory where the binaries generated by PH3 will live
PH3_BINGEN_ROOT = os.path.join(BIN_ROOT, 'gen', 'PH3', NUM_CLASSES)
# Directory where the media generated by PH3 will live
PH3_MEDIAGEN_ROOT = os.path.join(MEDIA_ROOT, 'gen', 'PH3', NUM_CLASSES)
# Because in ph3 we generate different data/binaries depending on the 
# conbination of choices of whether or not we do the ph2 transformations,
# whether or not we reduce the data, if applicable what reducer we use, and if
# applicable what kernel we use for our reducer, we use the following codes
PH3_W2_CODE = 'w2'
PH3_WO2_CODE = 'wo2'
PH3_WPH2_CODES = [PH3_W2_CODE, PH3_WO2_CODE]
PH3_REDUCER_NAME_PCA = 'pca'
PH3_REDUCER_NAME_KPCA = 'kpca'
PH3_REDUCER_NAME_UMAP = 'umap'
PH3_REDUCER_NAMES = [PH3_REDUCER_NAME_PCA,
                     PH3_REDUCER_NAME_KPCA,
                     PH3_REDUCER_NAME_UMAP]
PH3_REDUCER_KERNEL_NAME_POLY = 'poly'
PH3_REDUCER_KERNEL_NAME_RBF = 'rbf'
PH3_REDUCER_KERNEL_NAME_SIG = 'sigmoid'
PH3_REDUCER_KERNEL_NAME_COS = 'cosine'
PH3_REDUCER_KERNEL_NAMES = [PH3_REDUCER_KERNEL_NAME_POLY,
                            PH3_REDUCER_KERNEL_NAME_RBF,
                            PH3_REDUCER_KERNEL_NAME_SIG,
                            PH3_REDUCER_KERNEL_NAME_COS]

TRAIN_BINLOAD_ROOT = os.path.join(BIN_ROOT, 'load', 'TRAIN')
TRAIN_BINGEN_ROOT = os.path.join(BIN_ROOT, 'gen', 'TRAIN')
TRAIN_SCORES_ROOT = os.path.join(SCORES_ROOT)
TRAIN_KNN_CODE = 'KNN'
TRAIN_BERT_CODE = 'BERT'

################################## Filesystem #################################
###############################################################################
################################ Column naming ################################

## Video Identification columns
tag_columns = ["fileid", "person_id", "cycle_num", "handedness", "class_name"]
fileid_col = "fileid"
handedness_column = "handedness"

## Applicable only to per frame datasets
current_frame_col = "current_frame"

## Class columns
class_columns = ["class_numeric", "active_hand"]
### Sign class
class_name_column = "class_name"
class_numeric_column = "class_numeric"

### Active hand class
active_hand_col = "active_hand"

#/ Original landmarks
##/ Original hand landmarks
pf_hand_landmark_columns = []
for i in range(21):
  pf_hand_landmark_columns.append('h'+str(i)+'x')
  pf_hand_landmark_columns.append('h'+str(i)+'y')
  pf_hand_landmark_columns.append('h'+str(i)+'z')

##/ Original pose landmarks
pf_pose_landmark_columns = []
for i in [0, 11, 12]:
  pf_pose_landmark_columns.append('p'+str(i)+'x')
  pf_pose_landmark_columns.append('p'+str(i)+'y')
  pf_pose_landmark_columns.append('p'+str(i)+'z')

#/ Mean position landmarks
##/ Mean hand position landmarks
pf_mean_hand_columns = ["h_mean_x", "h_mean_y", "h_mean_z"]

#/ v1, v2, v3 vectors
#/ palm v1, v2, v3 vectors
pf_h_v123_columns = ["h_v1x", "h_v1y", "h_v1z"]+["h_v2x", "h_v2y", "h_v2z"]   \
+["h_v3x", "h_v3y", "h_v3z"]
#/ chest v1, v2, v3 vectors
pf_p_v123_columns = ["p_v1x", "p_v1y", "p_v1z"]+["p_v2x", "p_v2y", "p_v2z"]   \
+["p_v3x", "p_v3y", "p_v3z"]

#/ Rebased landmarks
##/ Rebased hand landmarks
pf_wrist_hand_landmark_columns = []
for i in range(21):
  pf_wrist_hand_landmark_columns.append('wh'+str(i)+'x')
  pf_wrist_hand_landmark_columns.append('wh'+str(i)+'y')
  pf_wrist_hand_landmark_columns.append('wh'+str(i)+'z')

##/ Rebased pose landmarks
pf_chest_pose_landmark_columns = []
for i in [0, 11, 12]:
  pf_chest_pose_landmark_columns.append('cp'+str(i)+'x')
  pf_chest_pose_landmark_columns.append('cp'+str(i)+'y')
  pf_chest_pose_landmark_columns.append('cp'+str(i)+'z')
pf_chest_pose_landmark_columns.append('cp_h_mean_x')
pf_chest_pose_landmark_columns.append('cp_h_mean_y')
pf_chest_pose_landmark_columns.append('cp_h_mean_z')


## Applicable only to per video dataset
pv_hand_landmark_columns = []
pv_pose_landmark_columns = []
pv_mean_hand_columns = []
pv_h_v123_columns = []
pv_p_v123_columns = []
pv_wrist_hand_landmark_columns = []
pv_chest_pose_landmark_columns = []


for k in range(NUM_FRAMES_PER_VIDEO):
  #/ Original landmarks
  ##/ Original hand landmarks
  for i in range(21):
    pv_hand_landmark_columns.append('f'+str(k)+'_h'+str(i)+'x')
    pv_hand_landmark_columns.append('f'+str(k)+'_h'+str(i)+'y')
    pv_hand_landmark_columns.append('f'+str(k)+'_h'+str(i)+'z')

  ##/ Original pose landmarks
  for i in [0, 11, 12]:
    pv_pose_landmark_columns.append('f'+str(k)+'_p'+str(i)+'x')
    pv_pose_landmark_columns.append('f'+str(k)+'_p'+str(i)+'y')
    pv_pose_landmark_columns.append('f'+str(k)+'_p'+str(i)+'z')

  ##/ Mean position landmarks
  ##/ Mean hand position landmarks
  pv_mean_hand_columns.append('f'+str(k)+'_h_mean_x')
  pv_mean_hand_columns.append('f'+str(k)+'_h_mean_y')
  pv_mean_hand_columns.append('f'+str(k)+'_h_mean_z')

  #/ v1, v2, v3 vectors
  for i in [1, 2, 3]:
    ##/ hand v1, v2, v3 vectors
    pv_h_v123_columns.append('f'+str(k)+'_h_v'+str(i)+'x')
    pv_h_v123_columns.append('f'+str(k)+'_h_v'+str(i)+'y')
    pv_h_v123_columns.append('f'+str(k)+'_h_v'+str(i)+'z')

    ##/ pose v1, v2, v3 vectors
    pv_p_v123_columns.append('f'+str(k)+'_p_v'+str(i)+'x')
    pv_p_v123_columns.append('f'+str(k)+'_p_v'+str(i)+'y')
    pv_p_v123_columns.append('f'+str(k)+'_p_v'+str(i)+'z')

  #/ Rebased landmarks
  ##/ Rebased hand landmarks
  for i in range(21):
    pv_wrist_hand_landmark_columns.append('f'+str(k)+'_wh'+str(i)+'x')
    pv_wrist_hand_landmark_columns.append('f'+str(k)+'_wh'+str(i)+'y')
    pv_wrist_hand_landmark_columns.append('f'+str(k)+'_wh'+str(i)+'z')

  ##/ Rebased pose landmarks
  for i in [0, 11, 12]:
    pv_chest_pose_landmark_columns.append('f'+str(k)+'_cp'+str(i)+'x')
    pv_chest_pose_landmark_columns.append('f'+str(k)+'_cp'+str(i)+'y')
    pv_chest_pose_landmark_columns.append('f'+str(k)+'_cp'+str(i)+'z')
  pv_chest_pose_landmark_columns.append('f'+str(k)+'_cp_h_mean_x')
  pv_chest_pose_landmark_columns.append('f'+str(k)+'_cp_h_mean_y')
  pv_chest_pose_landmark_columns.append('f'+str(k)+'_cp_h_mean_z')

################################ Column naming ################################
###############################################################################
################################ Score tracking ###############################

## KNN
knn_scores_columns = ["class_list", "accuracy", "data_unit", "PH2", "PH3", 
                      "reducer", "kernel", "n", "k"]
knn_score_tracker = []

## BERT
bert_scores_columns = ["class_list", "accuracy", "data_unit", "PH2", "PH3", 
                      "reducer", "kernel", "n", "loadble", "lr", "optimizer",
                      "loss_fn", "num_epochs"]
bert_score_tracker = []

best_scores = {
  TRAIN_KNN_CODE: {
                    DATA_AH_PF: {
                        "accuracy": -1,
                        "data_config": -1,
                        "train_config": -1
                    },
                    DATA_S_PF: {
                        "accuracy": -1,
                        "data_config": -1,
                        "train_config": -1
                    },
                    DATA_S_PV: {
                        "accuracy": -1,
                        "data_config": -1,
                        "train_config": -1
                    }
  },
  TRAIN_BERT_CODE: {
                    DATA_AH_PF: {
                        "accuracy": -1,
                        "data_config": -1,
                        "train_config": -1
                    },
                    DATA_S_PF: {
                        "accuracy": -1,
                        "data_config": -1,
                        "train_config": -1
                    },
                    DATA_S_PV: {
                        "accuracy": -1,
                        "data_config": -1,
                        "train_config": -1
                    }
  }
}

################################ Score tracking ###############################
###############################################################################